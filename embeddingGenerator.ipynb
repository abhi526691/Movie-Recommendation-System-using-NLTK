{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk, openai, time\n",
    "import ast  # For safely evaluating strings as lists\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Abhishek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Abhishek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Abhishek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ingest:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "        openai.api_key = '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'\n",
    "\n",
    "\n",
    "    def get_embedding(self, text, model=\"text-embedding-ada-002\"):\n",
    "            for i in range(3):\n",
    "                try:\n",
    "                    text = text.replace(\"\\n\", \" \").replace(\"start_para_\", \"\").replace(\n",
    "                        \"Title\", \"\").replace(\"header\", \"\").replace(\"subheader\", \"\")\n",
    "                    res = openai.Embedding.create(input=[text], model=model)[\n",
    "                        'data'][0]['embedding']\n",
    "                    \n",
    "                    return res\n",
    "                except Exception as e:\n",
    "                    print(\"gpt error wait 20 sec for retry\",flush=True)\n",
    "                    time.sleep(21)\n",
    "                    continue\n",
    "            return \"error\"\n",
    "\n",
    "    def compute_doc_embeddings(self, df: pd.DataFrame):\n",
    "        return {idx: self.get_embedding(r.Text) for idx, r in df.iterrows()}\n",
    "    \n",
    "    def load_embeddings(self, df):\n",
    "        max_dim = max([int(c) for c in df.columns if c != \"count\"])\n",
    "        return {\n",
    "            (r.count): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "        }\n",
    "\n",
    "    def process(self, data, mydir):\n",
    "        document_embeddings = self.compute_doc_embeddings(data)\n",
    "        final_df = pd.DataFrame(list(document_embeddings.items()), columns=['Index', 'embedding'])\n",
    "        final_df['Index'] = final_df['Index'].astype(int)\n",
    "        final_df['title'] = data['title']\n",
    "        final_df['Text'] = data['Text']\n",
    "        with open(mydir, 'a', encoding='utf-8') as f:\n",
    "            final_df.to_csv(f, header=f.tell()==0, index=False)\n",
    "        return final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Check if the input is a string\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [w for w in tokens if not w.lower() in stop_words]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(w) for w in filtered_tokens])\n",
    "\n",
    "    return lemmatized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list_data(data_str):\n",
    "    try:\n",
    "        # Safely evaluate string as a list\n",
    "        data_list = ast.literal_eval(data_str)\n",
    "        if isinstance(data_list, list):\n",
    "            # Flatten list to string\n",
    "            return ' '.join([str(item) for item in data_list])\n",
    "        return data_str\n",
    "    except:\n",
    "        return data_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Specify the columns to preprocess\n",
    "    list_columns = ['genres', 'keywords', 'cast', 'crew']\n",
    "    text_columns = ['original_language', 'overview', 'release_date', \n",
    "                    'production_companies', 'runtime', 'tagline', 'title']\n",
    "\n",
    "    # Flatten list data and preprocess\n",
    "    for col in list_columns:\n",
    "        df[col] = df[col].apply(flatten_list_data).apply(preprocess_text)\n",
    "\n",
    "    # Preprocess other text columns\n",
    "    for col in text_columns:\n",
    "        df[col] = df[col].apply(preprocess_text)\n",
    "\n",
    "    # Concatenate all features\n",
    "    df['combined_features'] = df[list_columns + text_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\AI and DataScience\\Step Presentation\\Movie-Recommendation-in-Django\\bingebot\\embeddingGenerator.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcsv/final_dataset.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_movies \u001b[39m=\u001b[39m load_and_preprocess(dataset_path)\n",
      "\u001b[1;32me:\\AI and DataScience\\Step Presentation\\Movie-Recommendation-in-Django\\bingebot\\embeddingGenerator.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Flatten list data and preprocess\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m list_columns:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     df[col] \u001b[39m=\u001b[39m df[col]\u001b[39m.\u001b[39;49mapply(flatten_list_data)\u001b[39m.\u001b[39;49mapply(preprocess_text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Preprocess other text columns\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m text_columns:\n",
      "File \u001b[1;32mc:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:4357\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4248\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4249\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4252\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4253\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FrameOrSeriesUnion:\n\u001b[0;32m   4254\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4255\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4256\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4355\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4356\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4357\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:1043\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1040\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m-> 1043\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:1098\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m   1093\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1099\u001b[0m             values,\n\u001b[0;32m   1100\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1101\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1102\u001b[0m         )\n\u001b[0;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1105\u001b[0m     \u001b[39m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m     \u001b[39m# so extension arrays can be used\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2859\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32me:\\AI and DataScience\\Step Presentation\\Movie-Recommendation-in-Django\\bingebot\\embeddingGenerator.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Lemmatize\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m lemmatizer \u001b[39m=\u001b[39m WordNetLemmatizer()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m lemmatized_text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([lemmatizer\u001b[39m.\u001b[39mlemmatize(w) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m filtered_tokens])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m lemmatized_text\n",
      "\u001b[1;32me:\\AI and DataScience\\Step Presentation\\Movie-Recommendation-in-Django\\bingebot\\embeddingGenerator.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Lemmatize\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m lemmatizer \u001b[39m=\u001b[39m WordNetLemmatizer()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m lemmatized_text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([lemmatizer\u001b[39m.\u001b[39;49mlemmatize(w) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m filtered_tokens])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI%20and%20DataScience/Step%20Presentation/Movie-Recommendation-in-Django/bingebot/embeddingGenerator.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m lemmatized_text\n",
      "File \u001b[1;32mc:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\stem\\wordnet.py:38\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize\u001b[39m(\u001b[39mself\u001b[39m, word, pos\u001b[39m=\u001b[39mNOUN):\n\u001b[1;32m---> 38\u001b[0m     lemmas \u001b[39m=\u001b[39m wordnet\u001b[39m.\u001b[39;49m_morphy(word, pos)\n\u001b[0;32m     39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmin\u001b[39m(lemmas, key\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m) \u001b[39mif\u001b[39;00m lemmas \u001b[39melse\u001b[39;00m word\n",
      "File \u001b[1;32mc:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:120\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    118\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLazyCorpusLoader object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 120\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load()\n\u001b[0;32m    121\u001b[0m \u001b[39m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attr)\n",
      "File \u001b[1;32mc:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:88\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     87\u001b[0m \u001b[39m# Load the corpus.\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m corpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__reader_cls(root, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# This is where the magic happens!  Transform ourselves into\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m# the corpus by modifying our own __dict__ and __class__ to\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39m# match that of the corpus.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m args, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs\n",
      "File \u001b[1;32mc:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1144\u001b[0m, in \u001b[0;36mWordNetCorpusReader.__init__\u001b[1;34m(self, root, omw_reader)\u001b[0m\n\u001b[0;32m   1141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lexnames\u001b[39m.\u001b[39mappend(lexname)\n\u001b[0;32m   1143\u001b[0m \u001b[39m# Load the indices for lemmas and synset offsets\u001b[39;00m\n\u001b[1;32m-> 1144\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_lemma_pos_offset_map()\n\u001b[0;32m   1146\u001b[0m \u001b[39m# load the exception file data into memory\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_exception_map()\n",
      "File \u001b[1;32mc:\\Users\\Abhishek\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1236\u001b[0m, in \u001b[0;36mWordNetCorpusReader._load_lemma_pos_offset_map\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1233\u001b[0m     \u001b[39mraise\u001b[39;00m WordNetError(\u001b[39m\"\u001b[39m\u001b[39mfile \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, line \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m tup)\n\u001b[0;32m   1235\u001b[0m \u001b[39m# map lemmas and parts of speech to synsets\u001b[39;00m\n\u001b[1;32m-> 1236\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lemma_pos_offset_map[lemma][pos] \u001b[39m=\u001b[39m synset_offsets\n\u001b[0;32m   1237\u001b[0m \u001b[39mif\u001b[39;00m pos \u001b[39m==\u001b[39m ADJ:\n\u001b[0;32m   1238\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lemma_pos_offset_map[lemma][ADJ_SAT] \u001b[39m=\u001b[39m synset_offsets\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_path = 'csv/final_dataset.csv'\n",
    "df_movies = load_and_preprocess(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Adventure Fantasy Action ocean drug abuse exotic island east india trading company love one 's life traitor shipwreck strong woman ship alliance calypso afterlife fighter pirate swashbuckler aftercreditsstinger Johnny Depp Orlando Bloom Keira Knightley Gore Verbinski en Captain Barbossa , long believed dead , come back life headed edge Earth Turner Elizabeth Swann . nothing quite seems . 2007-05-19 [ 'Walt Disney Pictures ' , 'Jerry Bruckheimer Films ' , 'Second Mate Productions ' ]  end world , adventure begin . Pirates Caribbean : World 's End\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies['combined_features'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    try:\n",
    "        response = openai.Embedding.create(input=[text], model=model)\n",
    "        return response['data'][0]['embedding']\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['embedding'] = df_movies['combined_features'].apply(lambda x: get_embedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>release_date</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>runtime</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>revenue</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>combined_features</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Action Adventure Fantasy ScienceFiction</td>\n",
       "      <td>culture clash future space war space colony so...</td>\n",
       "      <td>en</td>\n",
       "      <td>22nd century , paraplegic Marine dispatched mo...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>[ 'Ingenious Film Partners ' , 'Twentieth Cent...</td>\n",
       "      <td></td>\n",
       "      <td>Enter World Pandora .</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>Sam Worthington Zoe Saldana Sigourney Weaver</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Action Adventure Fantasy ScienceFiction cultur...</td>\n",
       "      <td>[-7.430189725710079e-05, -0.04472867399454117,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Adventure Fantasy Action</td>\n",
       "      <td>ocean drug abuse exotic island east india trad...</td>\n",
       "      <td>en</td>\n",
       "      <td>Captain Barbossa , long believed dead , come b...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>[ 'Walt Disney Pictures ' , 'Jerry Bruckheimer...</td>\n",
       "      <td></td>\n",
       "      <td>end world , adventure begin .</td>\n",
       "      <td>Pirates Caribbean : World 's End</td>\n",
       "      <td>Johnny Depp Orlando Bloom Keira Knightley</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>961000000</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Adventure Fantasy Action ocean drug abuse exot...</td>\n",
       "      <td>[-0.011351223103702068, -0.03744199126958847, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Action Adventure Crime</td>\n",
       "      <td>spy based novel secret agent sequel mi6 britis...</td>\n",
       "      <td>en</td>\n",
       "      <td>cryptic message Bond ’ past sends trail uncove...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>[ 'Columbia Pictures ' , 'Danjaq ' , 'B24 ' ]</td>\n",
       "      <td></td>\n",
       "      <td>Plan One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>Daniel Craig Christoph Waltz Léa Seydoux</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>880674609</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Action Adventure Crime spy based novel secret ...</td>\n",
       "      <td>[-0.011605915613472462, -0.016505299136042595,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Action Crime Drama Thriller</td>\n",
       "      <td>dc comic crime fighter terrorist secret identi...</td>\n",
       "      <td>en</td>\n",
       "      <td>Following death District Attorney Harvey Dent ...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>[ 'Legendary Pictures ' , 'Warner Bros. ' , 'D...</td>\n",
       "      <td></td>\n",
       "      <td>Legend Ends</td>\n",
       "      <td>Dark Knight Rises</td>\n",
       "      <td>Christian Bale Michael Caine Gary Oldman</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>1084939099</td>\n",
       "      <td>7.6</td>\n",
       "      <td>Action Crime Drama Thriller dc comic crime fig...</td>\n",
       "      <td>[-0.015744570642709732, -0.03931484371423721, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Action Adventure ScienceFiction</td>\n",
       "      <td>based novel mar medallion space travel princes...</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter war-weary , former military captai...</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>[ 'Walt Disney Pictures ' ]</td>\n",
       "      <td></td>\n",
       "      <td>Lost world , found another .</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>Taylor Kitsch Lynn Collins Samantha Morton</td>\n",
       "      <td>Andrew Stanton</td>\n",
       "      <td>284139100</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Action Adventure ScienceFiction based novel ma...</td>\n",
       "      <td>[0.0019912656862288713, -0.02921212464570999, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   genres  \\\n",
       "0           0  Action Adventure Fantasy ScienceFiction   \n",
       "1           1                 Adventure Fantasy Action   \n",
       "2           2                   Action Adventure Crime   \n",
       "3           3              Action Crime Drama Thriller   \n",
       "4           4          Action Adventure ScienceFiction   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  culture clash future space war space colony so...                en   \n",
       "1  ocean drug abuse exotic island east india trad...                en   \n",
       "2  spy based novel secret agent sequel mi6 britis...                en   \n",
       "3  dc comic crime fighter terrorist secret identi...                en   \n",
       "4  based novel mar medallion space travel princes...                en   \n",
       "\n",
       "                                            overview release_date  \\\n",
       "0  22nd century , paraplegic Marine dispatched mo...   2009-12-10   \n",
       "1  Captain Barbossa , long believed dead , come b...   2007-05-19   \n",
       "2  cryptic message Bond ’ past sends trail uncove...   2015-10-26   \n",
       "3  Following death District Attorney Harvey Dent ...   2012-07-16   \n",
       "4  John Carter war-weary , former military captai...   2012-03-07   \n",
       "\n",
       "                                production_companies runtime  \\\n",
       "0  [ 'Ingenious Film Partners ' , 'Twentieth Cent...           \n",
       "1  [ 'Walt Disney Pictures ' , 'Jerry Bruckheimer...           \n",
       "2      [ 'Columbia Pictures ' , 'Danjaq ' , 'B24 ' ]           \n",
       "3  [ 'Legendary Pictures ' , 'Warner Bros. ' , 'D...           \n",
       "4                        [ 'Walt Disney Pictures ' ]           \n",
       "\n",
       "                         tagline                             title  \\\n",
       "0          Enter World Pandora .                            Avatar   \n",
       "1  end world , adventure begin .  Pirates Caribbean : World 's End   \n",
       "2               Plan One Escapes                           Spectre   \n",
       "3                    Legend Ends                 Dark Knight Rises   \n",
       "4   Lost world , found another .                       John Carter   \n",
       "\n",
       "                                           cast               crew  \\\n",
       "0  Sam Worthington Zoe Saldana Sigourney Weaver      James Cameron   \n",
       "1     Johnny Depp Orlando Bloom Keira Knightley     Gore Verbinski   \n",
       "2      Daniel Craig Christoph Waltz Léa Seydoux         Sam Mendes   \n",
       "3      Christian Bale Michael Caine Gary Oldman  Christopher Nolan   \n",
       "4    Taylor Kitsch Lynn Collins Samantha Morton     Andrew Stanton   \n",
       "\n",
       "      revenue  vote_average  \\\n",
       "0  2787965087           7.2   \n",
       "1   961000000           6.9   \n",
       "2   880674609           6.3   \n",
       "3  1084939099           7.6   \n",
       "4   284139100           6.1   \n",
       "\n",
       "                                   combined_features  \\\n",
       "0  Action Adventure Fantasy ScienceFiction cultur...   \n",
       "1  Adventure Fantasy Action ocean drug abuse exot...   \n",
       "2  Action Adventure Crime spy based novel secret ...   \n",
       "3  Action Crime Drama Thriller dc comic crime fig...   \n",
       "4  Action Adventure ScienceFiction based novel ma...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-7.430189725710079e-05, -0.04472867399454117,...  \n",
       "1  [-0.011351223103702068, -0.03744199126958847, ...  \n",
       "2  [-0.011605915613472462, -0.016505299136042595,...  \n",
       "3  [-0.015744570642709732, -0.03931484371423721, ...  \n",
       "4  [0.0019912656862288713, -0.02921212464570999, ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.to_csv('movies_with_embedding.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def get_cosine_similarity(query_embedding, movie_embeddings):\n",
    "    # Reshape query embedding to match the shape of movie embeddings\n",
    "    query_embedding_reshaped = np.array(query_embedding).reshape(1, -1)\n",
    "    \n",
    "    # Compute cosine similarity between the query and each movie\n",
    "    similarity_scores = cosine_similarity(query_embedding_reshaped, movie_embeddings)[0]\n",
    "    \n",
    "    return similarity_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_movies(query, df_movies, top_n=5):\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = get_embedding(query)\n",
    "\n",
    "    # Assuming 'embedding' column in df_movies is already in the correct format\n",
    "    # Convert list of embeddings to a 2D numpy array\n",
    "    movie_embeddings = np.array(df_movies['embedding'].tolist())\n",
    "\n",
    "    # Get cosine similarity scores\n",
    "    similarity_scores = get_cosine_similarity(query_embedding, movie_embeddings)\n",
    "\n",
    "    # Add similarity scores to the dataframe\n",
    "    df_movies['similarity'] = similarity_scores\n",
    "\n",
    "    # Sort the movies based on similarity scores\n",
    "    sorted_movies = df_movies.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "    # Return the top N similar movies\n",
    "    return sorted_movies.head(top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                title  similarity  \\\n",
      "303                          Catwoman    0.828907   \n",
      "9    Batman v Superman : Dawn Justice    0.826492   \n",
      "163                          Watchmen    0.823052   \n",
      "119                     Batman Begins    0.819833   \n",
      "65                        Dark Knight    0.819453   \n",
      "\n",
      "                                  production_companies  \n",
      "303  [ 'Village Roadshow Pictures ' , 'DiNovi Pictu...  \n",
      "9    [ 'DC Comics ' , 'Atlas Entertainment ' , 'War...  \n",
      "163  [ 'Paramount Pictures ' , 'DC Comics ' , 'Lawr...  \n",
      "119  [ 'DC Comics ' , 'Legendary Pictures ' , 'Warn...  \n",
      "65   [ 'DC Comics ' , 'Legendary Pictures ' , 'Warn...  \n"
     ]
    }
   ],
   "source": [
    "# Example user query\n",
    "user_query = \"Suggest me a DC movie \"\n",
    "\n",
    "# Find top 5 similar movies\n",
    "top_movies = find_top_movies(user_query, df_movies)\n",
    "\n",
    "# Display the results\n",
    "print(top_movies[['title', 'similarity', 'production_companies']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def load_csv_and_convert_embeddings(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert the embedding string back to a numpy array\n",
    "    def convert_embedding(embedding_str):\n",
    "        try:\n",
    "            # Convert the string representation of the list back to a list\n",
    "            embedding_list = ast.literal_eval(embedding_str)\n",
    "            return np.array(embedding_list)\n",
    "        except:\n",
    "            # Return a zero array in case of any issue\n",
    "            return np.zeros(1024)\n",
    "\n",
    "    df['embedding'] = df['embedding'].apply(convert_embedding)\n",
    "    return df\n",
    "\n",
    "df_movies = load_csv_and_convert_embeddings('csv/movies_with_embedding.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "new_df = pd.read_csv('csv/movies_with_embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'genres', 'keywords', 'original_language', 'overview',\n",
       "       'release_date', 'production_companies', 'runtime', 'tagline', 'title',\n",
       "       'cast', 'crew', 'revenue', 'vote_average', 'combined_features',\n",
       "       'embedding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[['title', 'embedding']].to_csv('csv/bingebot_csv_with_embedding_title.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
